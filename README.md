<h2> Explainable AI Papers </h2>

<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(1).pdf" style="text-decoration:none;">Visualizing and Understanding Convolutional Networks</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(2).pdf" style="text-decoration:none;">On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(3).pdf" style="text-decoration:none;">This Looks Like That: Deep Learning for
Interpretable Image Recognition</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(4).pdf" style="text-decoration:none;">Understanding Neural Networks Through Deep Visualization</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(5).pdf" style="text-decoration:none;">Visualizing Deep Neural Network Decisions: Prediction Difference Analysis</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(6).pdf" style="text-decoration:none;">SmoothGrad: removing noise by adding noise</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(7).pdf" style="text-decoration:none;">Score-CAM:
Score-Weighted Visual Explanations for Convolutional Neural Networks</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(8).pdf" style="text-decoration:none;"> A Simple Saliency Method That Passes the Sanity Checks </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(9).pdf" style="text-decoration:none;">Object Detectors Emerge in Deep Scene CNNs</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(10).pdf" style="text-decoration:none;"> ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(11).pdf" style="text-decoration:none;">Explanation by Progressive Exaggeration</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(12).pdf" style="text-decoration:none;">Counterfactual Visual Explanations</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(13).pdf" style="text-decoration:none;">Using KL-divergence to focus Deep Visual Explanation</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(14).pdf" style="text-decoration:none;">Grad-CAM++: Improved Visual Explanations for Deep Convolutional Networks</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(15).pdf" style="text-decoration:none;">Understanding Black-box Predictions via Influence Functions</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(16).pdf" style="text-decoration:none;">Interpretable Image Recognition with Hierarchical Prototypes</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(17).pdf" style="text-decoration:none;">Interpretable Explanations of Black Boxes by Meaningful Perturbation</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(18).pdf" style="text-decoration:none;">Striving for Simplicity: The All Convolutional Net</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(19).pdf" style="text-decoration:none;">Bias Also Matters: Bias Attribution for Deep Neural Network Explanation</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(20).pdf" style="text-decoration:none;">Axiomatic Attribution for Deep Networks</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(21).pdf" style="text-decoration:none;">Network Dissection:
Quantifying Interpretability of Deep Visual Representations</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(22).pdf" style="text-decoration:none;">Anchors: High-Precision Model-Agnostic Explanations</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(23).pdf" style="text-decoration:none;">Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(24).pdf" style="text-decoration:none;">Understanding Deep Image Representations by Inverting Them</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(25).pdf" style="text-decoration:none;">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(26).pdf" style="text-decoration:none;">Towards Robust Interpretability
with Self-Explaining Neural Networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(27).pdf" style="text-decoration:none;">Towards better understanding of gradient-based attribution methods for Deep Neural Networks</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(28).pdf" style="text-decoration:none;">Interpretable Convolutional Neural Networks</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(29).pdf" style="text-decoration:none;">Understanding intermediate layers
using linear classifier probes </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(30).pdf" style="text-decoration:none;">Black Box Explanation by Learning Image Exemplars in the Latent Feature Space</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(31).pdf" style="text-decoration:none;">Sanity Checks for Saliency Maps</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(32).pdf" style="text-decoration:none;">Grad-CAM:
Visual Explanations from Deep Networks via Gradient-based Localization</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(33).pdf" style="text-decoration:none;">Learning Deep Features for Discriminative Localization</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(34).pdf" style="text-decoration:none;">An unexpected unity among methods for interpreting model predictions</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(35).pdf" style="text-decoration:none;">"Why Should I Trust You?"
Explaining the Predictions of Any Classifier</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(36).pdf" style="text-decoration:none;">The (Un) reliability of saliency methods</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(37).pdf" style="text-decoration:none;">Learning Important Features Through Propagating Activation Differences</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(38).pdf" style="text-decoration:none;">A Unified Approach to Interpreting Model Predictions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(39).pdf" style="text-decoration:none;">TED: Teaching AI to Explain its Decisions</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(40).pdf" style="text-decoration:none;">Understanding Deep Neural Networks For Regression In Leaf Counting</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(41).pdf" style="text-decoration:none;">Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Explainable-AI-Papers/blob/master/ex(42).pdf" style="text-decoration:none;">"Why did you do that?"
Explaining black box models with Inductive Synthesis</a></li>
 </ul>
